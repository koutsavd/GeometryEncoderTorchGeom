{
 "cells": [
  {
   "cell_type": "code",
   "id": "13a5a881846deaf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T01:47:47.750446Z",
     "start_time": "2025-05-20T01:31:01.637892Z"
    }
   },
   "source": [
    "# %%\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from pathlib import Path\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import random_split\n"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T01:31:02.540537Z",
     "start_time": "2025-05-20T01:31:02.535115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# %%\n",
    "class CarGraphDataset(Dataset):\n",
    "    def __init__(self, path, transform=None, pre_transform=None):\n",
    "        super().__init__(None, transform, pre_transform)\n",
    "        self.path = Path(path)\n",
    "        self.files_x = sorted([f for f in self.path.rglob(\"*.npz\") if \"_adj\" not in f.name])\n",
    "        self.files_adj = sorted([f for f in self.path.rglob(\"*.npz\") if \"_adj\" in f.name])\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.files_x)\n",
    "\n",
    "    def get(self, idx):\n",
    "        x_data = np.load(self.files_x[idx])\n",
    "        x = torch.tensor(x_data['x'], dtype=torch.float32)\n",
    "        a = sparse.load_npz(self.files_adj[idx]).tocoo()\n",
    "        edge_index = torch.tensor(np.vstack((a.row, a.col)), dtype=torch.long)\n",
    "        return Data(x=x, edge_index=edge_index)"
   ],
   "id": "e9dac8e2dc50d6bc",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T01:31:03.443681Z",
     "start_time": "2025-05-20T01:31:03.438298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# %%\n",
    "class GraphAutoEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder_gnn = GCNConv(in_channels, hidden_channels)\n",
    "        self.encoder_lin = torch.nn.Linear(hidden_channels, latent_dim)\n",
    "        self.decoder = torch.nn.Linear(latent_dim, in_channels)\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.encoder_gnn(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        z = self.encoder_lin(x)\n",
    "        return z\n",
    "\n",
    "    def decode(self, z_graph, batch):\n",
    "        return self.decoder(z_graph[batch])\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        z_node = self.encode(x, edge_index)\n",
    "        z_graph = global_mean_pool(z_node, batch)\n",
    "        x_hat = self.decode(z_graph, batch)\n",
    "        return z_node, z_graph, x_hat, edge_index"
   ],
   "id": "e589d773d24802cf",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T01:34:22.277677Z",
     "start_time": "2025-05-20T01:34:22.273017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# %%\n",
    "class LitGraphAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, in_channels, hidden_channels, latent_dim, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = GraphAutoEncoder(in_channels, hidden_channels, latent_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.model(data)\n",
    "\n",
    "    def compute_adj_loss(self, z_node, edge_index):\n",
    "        z_i = z_node[edge_index[0]]\n",
    "        z_j = z_node[edge_index[1]]\n",
    "        dot_products = (z_i * z_j).sum(dim=1)\n",
    "        adj_pred = torch.sigmoid(dot_products)\n",
    "        adj_true = torch.ones_like(adj_pred)\n",
    "        return F.binary_cross_entropy(adj_pred, adj_true)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        z_node, _, x_hat, edge_index = self(batch)\n",
    "        loss_x = F.mse_loss(x_hat, batch.x)\n",
    "        loss_a = self.compute_adj_loss(z_node, edge_index)\n",
    "        loss = loss_x + loss_a\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        z_node, _, x_hat, edge_index = self(batch)\n",
    "        loss_x = F.mse_loss(x_hat, batch.x)\n",
    "        loss_a = self.compute_adj_loss(z_node, edge_index)\n",
    "        val_loss = loss_x + loss_a\n",
    "        self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return val_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        z_node, _, x_hat, edge_index = self(batch)\n",
    "        loss_x = F.mse_loss(x_hat, batch.x)\n",
    "        loss_a = self.compute_adj_loss(z_node, edge_index)\n",
    "        test_loss = loss_x + loss_a\n",
    "        self.log(\"test_loss\", test_loss, prog_bar=True)\n",
    "        return test_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)"
   ],
   "id": "ac42a679fe0c3936",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# %%\n",
    "# ---- TRAINING SECTION ---- #\n",
    "dataset = CarGraphDataset(\"/Users/koutsavd/PycharmProjects/Geometry_GNN/Graphs\")\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=4)\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    "    filename=\"best-graph-ae-{epoch:02d}-{val_loss:.4f}\",\n",
    "    save_weights_only=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "progress_cb = TQDMProgressBar(refresh_rate=10)\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"graph_autoencoder\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    callbacks=[checkpoint_cb, progress_cb],\n",
    "    logger=logger,\n",
    "    log_every_n_steps=1,\n",
    ")\n",
    "\n",
    "model = LitGraphAutoEncoder(in_channels=8, hidden_channels=32, latent_dim=64)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import IPython\n",
    "os._exit(00)"
   ],
   "id": "5d9748d10a270c87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "744d8c90cf964918"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
